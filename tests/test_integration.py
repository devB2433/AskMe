#!/usr/bin/env python3
"""ç³»ç»Ÿé›†æˆæµ‹è¯•è„šæœ¬"""

import sys
import os
import asyncio
import time
from pathlib import Path
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
backend_path = os.path.join(project_root, 'backend')
sys.path.insert(0, backend_path)
sys.path.insert(0, project_root)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class IntegrationTestSuite:
    """é›†æˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å¥—ä»¶"""
        self.test_results = []
        self.passed_tests = 0
        self.failed_tests = 0
    
    def run_test(self, test_name: str, test_func):
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        try:
            logger.info(f"å¼€å§‹æµ‹è¯•: {test_name}")
            start_time = time.time()
            
            result = test_func()
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result:
                logger.info(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡ (è€—æ—¶: {duration:.2f}s)")
                self.passed_tests += 1
                self.test_results.append((test_name, True, duration))
                return True
            else:
                logger.error(f"âœ— {test_name} æµ‹è¯•å¤±è´¥ (è€—æ—¶: {duration:.2f}s)")
                self.failed_tests += 1
                self.test_results.append((test_name, False, duration))
                return False
                
        except Exception as e:
            logger.error(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            self.failed_tests += 1
            self.test_results.append((test_name, False, 0))
            return False
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        total_tests = self.passed_tests + self.failed_tests
        success_rate = (self.passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        logger.info("\n" + "="*50)
        logger.info("ç³»ç»Ÿé›†æˆæµ‹è¯•æ€»ç»“:")
        logger.info(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"é€šè¿‡æµ‹è¯•: {self.passed_tests}")
        logger.info(f"å¤±è´¥æµ‹è¯•: {self.failed_tests}")
        logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info("="*50)
        
        for test_name, passed, duration in self.test_results:
            status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
            logger.info(f"  {status}: {test_name} ({duration:.2f}s)")
        
        return self.failed_tests == 0

def test_document_processing_pipeline():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†æµæ°´çº¿"""
    try:
        from services.document_processor import DocumentProcessor, ProcessingConfig
        from services.chunking_engine import ChunkingEngine
        from services.metadata_extractor import MetadataExtractor
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_content = """è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯æ–‡æ¡£å¤„ç†æµæ°´çº¿ã€‚
        æ–‡æ¡£åŒ…å«å¤šä¸ªæ®µè½å’Œä¸åŒçš„å†…å®¹ç±»å‹ã€‚
        è¿™æ˜¯ç¬¬äºŒæ®µå†…å®¹ï¼Œç”¨æ¥æµ‹è¯•åˆ†å—åŠŸèƒ½ã€‚
        ç¬¬ä¸‰æ®µå†…å®¹ç”¨äºéªŒè¯å…ƒæ•°æ®æå–åŠŸèƒ½ã€‚"""
        
        test_file = Path("test_integration_doc.txt")
        test_file.write_text(test_content, encoding='utf-8')
        
        try:
            # åˆå§‹åŒ–ç»„ä»¶
            processor = DocumentProcessor()
            chunking_engine = ChunkingEngine()
            metadata_extractor = MetadataExtractor()
            
            # å¤„ç†æ–‡æ¡£
            config = ProcessingConfig(chunk_size=100, chunk_overlap=20)
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯ProcessingConfig
            result = processor.process_document(str(test_file), config)
            
            # éªŒè¯ç»“æœ
            assert result is not None, "å¤„ç†ç»“æœä¸åº”ä¸ºç©º"
            assert len(result.chunks) > 0, "åº”è¯¥ç”Ÿæˆåˆ†å—"
            assert result.metadata is not None, "åº”è¯¥åŒ…å«å…ƒæ•°æ®"
            
            # éªŒè¯åˆ†å—
            chunks = chunking_engine.smart_chunk_text(test_content, config)
            assert len(chunks) > 0, "æ™ºèƒ½åˆ†å—åº”è¯¥ç”Ÿæˆç»“æœ"
            
            # éªŒè¯å…ƒæ•°æ®
            metadata = metadata_extractor.extract_from_text(test_content)
            assert metadata is not None, "å…ƒæ•°æ®æå–åº”è¯¥æˆåŠŸ"
            
            logger.info("æ–‡æ¡£å¤„ç†æµæ°´çº¿æµ‹è¯•é€šè¿‡")
            return True
            
        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            if test_file.exists():
                test_file.unlink()
                
    except Exception as e:
        logger.error(f"æ–‡æ¡£å¤„ç†æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_vector_storage_integration():
    """æµ‹è¯•å‘é‡å­˜å‚¨é›†æˆ"""
    try:
        from services.milvus_integration import MilvusClient
        from services.embedding_encoder import EmbeddingEncoder
        
        # åˆå§‹åŒ–ç»„ä»¶
        try:
            milvus_client = MilvusClient()
            encoder = EmbeddingEncoder()
        except Exception as e:
            logger.warning(f"Milvuså®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½æœåŠ¡æœªå¯åŠ¨ï¼‰: {e}")
            return True  # è·³è¿‡æ­¤æµ‹è¯•
        
        # æµ‹è¯•ç¼–ç åŠŸèƒ½
        test_texts = ["è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•å¥å­", "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•å¥å­"]
        embeddings = encoder.encode_batch(test_texts)
        
        assert len(embeddings) == len(test_texts), "ç¼–ç ç»“æœæ•°é‡åº”è¯¥åŒ¹é…"
        assert len(embeddings[0]) > 0, "ç¼–ç å‘é‡ä¸åº”è¯¥ä¸ºç©º"
        
        logger.info("å‘é‡å­˜å‚¨é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"å‘é‡å­˜å‚¨é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_search_service_integration():
    """æµ‹è¯•æœç´¢æœåŠ¡é›†æˆ"""
    try:
        from services.search_service import SearchService
        from services.query_processor import QueryProcessor
        from services.result_ranking import ResultRanker
        
        # åˆå§‹åŒ–ç»„ä»¶
        search_service = SearchService()
        query_processor = QueryProcessor()
        ranker = ResultRanker()
        
        # æµ‹è¯•æŸ¥è¯¢å¤„ç†
        query = "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•"
        processed_query = query_processor.process_query(query)
        
        assert processed_query.original_query == query, "åŸå§‹æŸ¥è¯¢åº”è¯¥ä¿æŒä¸å˜"
        assert len(processed_query.tokens) > 0, "åº”è¯¥ç”Ÿæˆåˆ†è¯ç»“æœ"
        
        # æµ‹è¯•ç»“æœæ’åº
        mock_results = [
            {"score": 0.8, "content": "ç›¸å…³å†…å®¹1"},
            {"score": 0.6, "content": "ç›¸å…³å†…å®¹2"},
            {"score": 0.9, "content": "ç›¸å…³å†…å®¹3"}
        ]
        
        ranked_results = ranker.rank_results(mock_results)
        assert len(ranked_results) == len(mock_results), "ç»“æœæ•°é‡åº”è¯¥ä¿æŒä¸€è‡´"
        
        # éªŒè¯æ’åºæ­£ç¡®æ€§
        for i in range(len(ranked_results) - 1):
            assert ranked_results[i]['score'] >= ranked_results[i + 1]['score'], "ç»“æœåº”è¯¥æŒ‰åˆ†æ•°é™åºæ’åˆ—"
        
        logger.info("æœç´¢æœåŠ¡é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"æœç´¢æœåŠ¡é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_qa_system_integration():
    """æµ‹è¯•é—®ç­”ç³»ç»Ÿé›†æˆ"""
    try:
        from services.context_manager import ContextManager
        from services.document_retriever import DocumentRetriever
        from services.answer_generator import AnswerGenerator
        
        # åˆå§‹åŒ–ç»„ä»¶
        context_manager = ContextManager()
        retriever = DocumentRetriever()
        answer_generator = AnswerGenerator()
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†
        session_id = "test_session_001"
        context_window = context_manager.get_session(session_id)
        assert context_window is not None, "åº”è¯¥èƒ½å¤Ÿè·å–ä¸Šä¸‹æ–‡çª—å£"
        
        # æµ‹è¯•ç­”æ¡ˆç”Ÿæˆï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
        question = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        mock_context = {
            "retrieved_documents": [
                {"content": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯", "score": 0.9},
                {"content": "æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦ç»„æˆéƒ¨åˆ†", "score": 0.8}
            ]
        }
        
        answer_result = answer_generator.generate_answer(question, mock_context)
        assert answer_result is not None, "åº”è¯¥ç”Ÿæˆç­”æ¡ˆç»“æœ"
        assert len(answer_result.answer) > 0, "ç­”æ¡ˆå†…å®¹ä¸åº”è¯¥ä¸ºç©º"
        
        logger.info("é—®ç­”ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"é—®ç­”ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_workflow_engine_integration():
    """æµ‹è¯•å·¥ä½œæµå¼•æ“é›†æˆ"""
    try:
        from services.workflow_definition import WorkflowBuilder
        from services.task_executor import TaskExecutor
        from services.state_manager import StateManager
        
        # åˆå§‹åŒ–ç»„ä»¶
        builder = WorkflowBuilder()
        task_executor = TaskExecutor()
        state_manager = StateManager()
        
        # æµ‹è¯•å·¥ä½œæµåˆ›å»º
        workflow = builder.create_document_processing_workflow()
        assert workflow is not None, "åº”è¯¥èƒ½å¤Ÿåˆ›å»ºå·¥ä½œæµ"
        assert len(workflow.nodes) > 0, "å·¥ä½œæµåº”è¯¥åŒ…å«èŠ‚ç‚¹"
        
        # æµ‹è¯•çŠ¶æ€ç®¡ç†
        state_id = state_manager.create_state(
            state_type="test",
            entity_id="test_entity_001",
            initial_data={"test": "data"}
        )
        assert state_id is not None, "åº”è¯¥èƒ½å¤Ÿåˆ›å»ºçŠ¶æ€è®°å½•"
        
        state_record = state_manager.get_state(state_id)
        assert state_record is not None, "åº”è¯¥èƒ½å¤Ÿè·å–çŠ¶æ€è®°å½•"
        
        logger.info("å·¥ä½œæµå¼•æ“é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"å·¥ä½œæµå¼•æ“é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_api_layer_integration():
    """æµ‹è¯•APIå±‚é›†æˆ"""
    try:
        # æµ‹è¯•APIè·¯ç”±å¯¼å…¥
        from routes.document_api import router as document_router
        from main import app
        
        # éªŒè¯FastAPIåº”ç”¨
        assert app is not None, "FastAPIåº”ç”¨åº”è¯¥åˆå§‹åŒ–æˆåŠŸ"
        assert len(app.routes) > 0, "åº”è¯¥åŒ…å«è·¯ç”±"
        
        # éªŒè¯æ–‡æ¡£APIè·¯ç”±
        assert document_router is not None, "æ–‡æ¡£APIè·¯ç”±åº”è¯¥å­˜åœ¨"
        
        logger.info("APIå±‚é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"APIå±‚é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹ç³»ç»Ÿé›†æˆæµ‹è¯•")
    logger.info("=" * 50)
    
    test_suite = IntegrationTestSuite()
    
    # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("æ–‡æ¡£å¤„ç†æµæ°´çº¿", test_document_processing_pipeline),
        ("å‘é‡å­˜å‚¨é›†æˆ", test_vector_storage_integration),
        ("æœç´¢æœåŠ¡é›†æˆ", test_search_service_integration),
        ("é—®ç­”ç³»ç»Ÿé›†æˆ", test_qa_system_integration),
        ("å·¥ä½œæµå¼•æ“é›†æˆ", test_workflow_engine_integration),
        ("APIå±‚é›†æˆ", test_api_layer_integration)
    ]
    
    # æ‰§è¡Œæµ‹è¯•
    for test_name, test_func in test_cases:
        test_suite.run_test(test_name, test_func)
    
    # è¾“å‡ºæ€»ç»“
    success = test_suite.print_summary()
    
    if success:
        logger.info("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ï¼")
    else:
        logger.error("âŒ éƒ¨åˆ†é›†æˆæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—")
    
    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)